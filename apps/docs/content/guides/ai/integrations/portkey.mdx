---
id: 'ai-integration-portkey'
title: 'Portkey AI'
subtitle: 'Learn how to integrate Supabase with Portkey AI, a control panel for your AI Applications'
breadcrumb: 'AI Integrations'
---

[Portkey AI](https://app.portkey.ai/?utm_source=supabase&utm_medium=content&utm_campaign=external) is a platform that simplifies AI integration for developers and organizations. With Portkey, you can access and manage over 250 AI models through a unified interface, providing enhanced control, visibility, and security for your generative AI applications.

## Introduction

This guide will show you how to use Portkey AI to generate embeddings with OpenAI and store them in a Supabase database. Portkey supports multiple AI providers, including Cohere, Voyage AI, Fireworks, Google Vertex AI, and OpenAI, all through a single API.

By using Portkey, companies build production-ready AI applications up to 10x faster with greater reliability.


## Prerequisites

- A Supabase project API Key and
- [Portkey AI](https://app.portkey.ai/?utm_source=supabase&utm_medium=content&utm_campaign=external) API key

## Setting up your environment

First, let's set up our Python environment with the necessary libraries:

```python
!pip install portkey-ai supabase
```


## Preparing your database
1. Create a Supabase account
2. Enable `pgvector`, an extension for PostgreSQL that allows you to both store and query vector embeddings within your database. Let's try it out.

First we'll enable the Vector extension. In Supabase, this can be done from the web portal through Database â†’ Extensions. You can also do this in SQL by running:

```sql
create extension vector;
```

3. Next let's create a table to store our documents and their embeddings:
`pgvector` introduces a new data type called `vector`. In the code above, we create a column named `embedding` with the `vector` data type. The size of the vector defines how many dimensions the vector holds. OpenAI's `text-embedding-ada-002` model outputs 1536 dimensions, so we will use that for our vector size.
We also create a `text` column named `content` to store the original document text that produced this embedding. Depending on your use case, you might just store a reference (URL or foreign key) to a document here instead.
```sql
create table documents (
  id bigserial primary key,
  content text,
  embedding vector(1536)
);
```

## Configuring Supabase and Portkey

Next, we'll import the required libraries and set up our Supabase and Portkey clients:

```python
from portkey_ai import Portkey
from supabase import create_client, Client

# Supabase setup
supabase_url = "YOUR_SUPABASE_PROJECT_URL"
supabase_key = "YOUR_SUPABASE_API_KEY"
supabase: Client = create_client(supabase_url, supabase_key)

# Portkey setup
portkey_client = Portkey(
    api_key="YOUR_PORTKEY_API_KEY",
    provider="openai",
    virtual_key="YOUR_OPENAI_VIRTUAL_KEY",
)
```

Replace the placeholder values with your actual Supabase and Portkey credentials.


## Generating and storing embeddings

Now, let's create a function to generate embeddings using Portkey and OpenAI, and store them in Supabase:

```python
#Generate Embedding
embedding_response = client.embeddings.create(
  model="text-embedding-ada-002",
  input="The food was delicious and the waiter...",
  encoding_format="float"
)


embedding = embedding_response.data[0].embedding

# Store in Supabase
result = supabase.table('documents').insert({
    "content": text,
    "embedding": embedding
    }).execute()



```

This function takes a text input, generates an embedding using  through Portkey, and then stores both the original text and its embedding in the Supabase `documents` table.

Portkey supports 250+ Models, you can choose any model just by changing the `provider` and `virtual_key`

Here's an example on how to use `Cohere` with Portkey

```python
client = Portkey(
    api_key="YOUR_PORTKEY_API_KEY", # defaults to os.environ.get("PORTKEY_API_KEY")
    provider="cohere",
    virtual_key="YOUR_COHERE_VIRTUAL_KEY",
)

embeddings = client.embeddings.create(
  model="embed-english-v3.0",
  input_type="search_query",
  input="The food was delicious and the waiter...",
  encoding_format="float"
)
```

- Note you will need to make a new table with `1024` dimensions instead of `1536` dimensions for Cohere's `embed-english-v3.0` model.


## Resources
- [Portkey AI docs](https://docs.portkey.ai/docs/introduction/what-is-portkey?utm_source=supabase&utm_medium=supabase&utm_campaign=external_integration)
- [Portkey's OpenSource AI Gateway](https://github.com/Portkey-AI/gateway?utm_source=supabase&utm_medium=supabase&utm_campaign=external_integration)
- [Join Portkey's Discord channel](https://discord.gg/portkey-llms-in-prod-1143393887742861333)

 


## Conclusion

This guide demonstrated how to use Portkey AI with OpenAI to generate embeddings and store them in a Supabase database. You can now easily create and query vector embeddings in your applications, leveraging the power of Portkey AI for model management and Supabase for data storage.
